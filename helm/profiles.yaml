daskhub:
  jupyterhub:
    singleuser:
      profileList:
        # Python singleuser -----------------------------------------------------
        - display_name: "CPU - Python"
          default: "True"
          description: '4 cores, 32 GiB of memory. <a href="https://github.com/pangeo-data/pangeo-docker-images">Pangeo Notebook</a> environment.'
          kubespawner_override:
            image: "${python_image}"
            cpu_guarantee: 3
            cpu_limit: 4
            mem_guarantee: "25G"
            mem_limit: "32G"
            default_url: "/lab/tree/PlanetaryComputerExamples/README.md"
            node_affinity_required:
              - matchExpressions:
                - key: pc.microsoft.com/userkind
                  operator: NotIn
                  values:
                  - gpu

        # Spark -----------------------------------------------------
        - display_name: "PySpark"
          default: "True"
          description: '4 cores, 32 GiB of memory. <a href="https://github.com/pangeo-data/pangeo-docker-images" target="_blank">Pangeo Notebook</a> environment powered by <a href="https://rasterframes.io/">Raster Frames</a>, <a href="http://geotrellis.io/">GeoTrellis</a> and <a href="https://spark.apache.org/">Apache Spark</a>.'
          kubespawner_override:
            image: "${pyspark_image}"
            cpu_guarantee: 3
            cpu_limit: 4
            mem_guarantee: "25G"
            mem_limit: "32G"
            default_url: "/lab/tree/PlanetaryComputerExamples/README.md"
            node_affinity_required:
              - matchExpressions:
                - key: pc.microsoft.com/userkind
                  operator: NotIn
                  values:
                  - gpu

        # R --------------------------------------------------------------------
        - display_name: "R"
          description: '8 cores, 64 GiB of memory. R geospatial environment.'
          kubespawner_override:
            image: "${r_image}"
            cpu_guarantee: 7.0
            cpu_limit: 8
            mem_guarantee: "54G"
            mem_limit: "59G"
            default_url: "/lab/tree/PlanetaryComputerExamples/README.md"
            node_affinity_required:
              - matchExpressions:
                - key: pc.microsoft.com/userkind
                  operator: NotIn
                  values:
                  - gpu

        # gpu-pytorch -------------------------------------------------------------
        - display_name: "GPU - PyTorch"
          description: '4 cores, 28 GiB of memory, <a href="https://docs.microsoft.com/en-us/azure/virtual-machines/nct4-v3-series">T4 GPU</a>. This has a longer startup time.'
          kubespawner_override:
            cpu_guarantee: 3.0
            cpu_limit: 4
            image: "${gpu_pytorch_image}"
            mem_limit: "27G"
            mem_guarantee: "20G"
            extra_resource_limits: {"nvidia.com/gpu": "1"}
            default_url: "/lab/tree/PlanetaryComputerExamples/README.md"
            tolerations:
              - key: 'nvidia.com/gpu'
                operator: 'Equal'
                value: 'present'
                effect: 'NoSchedule'
              - key: 'hub.jupyter.org_dedicated'
                operator: 'Equal'
                value: 'user'
                effect: 'NoSchedule'
            node_affinity_required:
              - matchExpressions:
                - key: pc.microsoft.com/userkind
                  operator: In
                  values:
                  - gpu

        # gpu-tensorflow ----------------------------------------------------------
        - display_name: "GPU - Tensorflow"
          description: '4 cores, 28 GiB of memory, <a href="https://docs.microsoft.com/en-us/azure/virtual-machines/nct4-v3-series">T4 GPU</a>. This has a longer startup time.'
          kubespawner_override:
            cpu_guarantee: 3.0
            cpu_limit: 4
            image: "${gpu_tensorflow_image}"
            mem_limit: "27G"
            mem_guarantee: "20G"
            extra_resource_limits: {"nvidia.com/gpu": "1"}
            default_url: "/lab/tree/PlanetaryComputerExamples/README.md"
            tolerations:
              - key: 'nvidia.com/gpu'
                operator: 'Equal'
                value: 'present'
                effect: 'NoSchedule'
              - key: 'hub.jupyter.org_dedicated'
                operator: 'Equal'
                value: 'user'
                effect: 'NoSchedule'
            node_affinity_required:
              - matchExpressions:
                - key: pc.microsoft.com/userkind
                  operator: In
                  values:
                  - gpu


        # QGIS -----------------------------------------------------------------
        - display_name: "QGIS (preview)"
          description: '4 cores, 32 GiB of memory. QGIS geospatial environment. Currently in preview mode. <a ref="mailto:planetarycomputer@microsoft.com">Contact us</a> with feedback.'
          kubespawner_override:
            image: "${qgis_image}"
            cpu_guarantee: 3
            cpu_limit: 4
            mem_guarantee: "24G"
            mem_limit: "30G"
            default_url: "/desktop"
            node_affinity_required:
              - matchExpressions:
                - key: pc.microsoft.com/userkind
                  operator: NotIn
                  values:
                  - gpu

      extraFiles:
        spark_default_configuration:
          # TODO(https://github.com/hashicorp/terraform-provider-helm/issues/628): use set-file
          stringData: |
            """
            Default Spark configuration init for the Jypyter instance.
            """
            import socket
            import os
            notebook_ip = socket.gethostbyname(socket.gethostname())
            namespace_user = os.environ.get('NAMESPACE_USER', '')
            spark_config = {
                'spark.master': 'k8s://https://kubernetes.default.svc.cluster.local',
                'spark.app.name': 'STAC API with RF in K8S',
                'spark.ui.port': '4040',
                'spark.driver.blockManager.port': '7777',
                'spark.driver.port': '2222',
                'spark.driver.host': notebook_ip,
                'spark.driver.bindAddress': '0.0.0.0',
                'spark.executor.instances': '2',
                'spark.executor.memory': '4g',
                'spark.driver.memory': '1g',
                'spark.executor.cores': '3',
                'spark.kubernetes.namespace': namespace_user,
                'spark.kubernetes.container.image': 'quay.io/daunnc/spark-k8s-py-3.8.8-gdal32-msftpc:3.1.2',
                'spark.kubernetes.executor.deleteOnTermination': 'true',
                'spark.kubernetes.authenticate.driver.serviceAccountName': 'default',
                'spark.kubernetes.authenticate.caCertFile': '/var/run/secrets/kubernetes.io/serviceaccount/ca.crt',
                'spark.kubernetes.authenticate.oauthTokenFile': '/var/run/secrets/kubernetes.io/serviceaccount/token',
                'spark.kubernetes.executor.podTemplateFile': '/etc/spark/executor-template.yml',
                'spark.kubernetes.node.selector.k8s.spark.org/dedicated': 'worker',
                'spark.kubernetes.node.selector.pc.microsoft.com/workerkind': 'spark-cpu',
                'spark.kubernetes.node.selector.kubernetes.azure.com/scalesetpriority': 'spot'
            }

        # Spark supports pool with no taints and can select nodes via selector only by default
        # This template allows Spark executors to make use of Azure spots
        spark_executor_template:
          stringData: |
            #
            # Licensed to the Apache Software Foundation (ASF) under one or more
            # contributor license agreements.  See the NOTICE file distributed with
            # this work for additional information regarding copyright ownership.
            # The ASF licenses this file to You under the Apache License, Version 2.0
            # (the "License"); you may not use this file except in compliance with
            # the License.  You may obtain a copy of the License at
            #
            #    http://www.apache.org/licenses/LICENSE-2.0
            #
            # Unless required by applicable law or agreed to in writing, software
            # distributed under the License is distributed on an "AS IS" BASIS,
            # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
            # See the License for the specific language governing permissions and
            # limitations under the License.
            #
            apiVersion: v1
            Kind: Pod
            metadata:
              labels:
                template-label-key: executor-template-label-value
            spec:
              containers:
              - name: test-executor-container
                image: will-be-overwritten
              # extra toleration to support Spot instances
              tolerations:
              - key: "kubernetes.azure.com/scalesetpriority"
                operator: "Equal"
                value: "spot"
                effect: "NoSchedule"
